#!/bin/sh

# ISO639
LANG="ca"

# ISO 3166-1 ALPHA-2
LOCALE="ES"

# Full Language Name
LANGFULL="catalan"

ENCODING="ISO8859-2"

# IDENTIFIER="${LANG}_${LOCALE}"
IDENTIFIER="ca"

echo "Creating PostgreSQL dictionary files for \"$IDENTIFIER\"";
mkdir -p ./dist ./temp;

for ext in aff dic; do
	if [ ! -e "./temp/$IDENTIFIER.utf8.$ext" ]; then
		## Download and convert to UTF-8 from $ENCODING
    wget --no-verbose "https://raw.githubusercontent.com/LibreOffice/dictionaries/master/$IDENTIFIER/dictionaries/$IDENTIFIER.$ext" -O - |
		iconv -f "$ENCODING" -t utf8 -o "./temp/$IDENTIFIER.utf8.$ext";
	fi;
done;


## Download the stop words if they don't exist, no one packages them
if [ ! -e "./dist/$LANGFULL.stop" ]; then
	wget --no-verbose "https://raw.githubusercontent.com/stopwords-iso/stopwords-$LANG/master/stopwords-$LANG.txt" -O "./dist/$LANGFULL.stop";
fi

## also a bit of processing..
# 1. PostgreSQL wants .affix and .dict,
#    LibreOffice uses .aff and .dic
# 2. Remove first line of dic (from docs)
#    > The first  line of the dictionaries (except personal dictionaries) contains
#    > the approximate word count (for optimal hash memory  size).
# 3. Removes blank lines (if they exist) and sorts dict
sed -e '1d' -e '/^$/d' "./temp/$IDENTIFIER.utf8.dic" | sort > "./dist/$IDENTIFIER.dict"
cp "./temp/$IDENTIFIER.utf8.aff" "./dist/$IDENTIFIER.affix"

rm -rf ./temp/

cat <<EOF


--
-- Run this on the database
--
CREATE TEXT SEARCH DICTIONARY ${LANGFULL}_hunspell (
	TEMPLATE  = ispell,
	DictFile  = $IDENTIFIER,
	AffFile   = $IDENTIFIER,
	StopWords = $LANGFULL
);
COMMENT ON TEXT SEARCH DICTIONARY ${LANGFULL}_hunspell
	IS '[USER ADDED] Hunspell dictionary for $LANGFULL';
CREATE TEXT SEARCH CONFIGURATION public.$LANGFULL (
	COPY = pg_catalog.english
);
ALTER TEXT SEARCH CONFIGURATION $LANGFULL
	ALTER MAPPING
	FOR
		asciiword, asciihword, hword_asciipart,  word, hword, hword_part
	WITH
		${LANGFULL}_hunspell, simple;
COMMENT ON TEXT SEARCH CONFIGURATION $LANGFULL
	IS '[USER ADDED] configuration for $LANGFULL';
EOF
